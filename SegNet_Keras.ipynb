{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SegNet\n",
    "\n",
    "We implement the SegNet architecture ([Badrinarayanan et al. 2015](https://arxiv.org/abs/1511.00561)) using the Keras framework.\n",
    "\n",
    "![](./img/SegNet_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_batches import load_png_3bands, load_png_1band, load_tif_3bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data\n",
    "x_validation = load_png_3bands(\"/Users/ikersanchez/Vizzuality/PROIEKTUAK/Skydipper/Data/dataset1/images_prepped_test/*.png\")\n",
    "y_validation = load_png_1band(\"/Users/ikersanchez/Vizzuality/PROIEKTUAK/Skydipper/Data/dataset1/annotations_prepped_test/*.png\")\n",
    "\n",
    "# Train data\n",
    "x_train = load_png_3bands(\"/Users/ikersanchez/Vizzuality/PROIEKTUAK/Skydipper/Data/dataset1/images_prepped_train/*.png\")\n",
    "y_train = load_png_1band(\"/Users/ikersanchez/Vizzuality/PROIEKTUAK/Skydipper/Data/dataset1/annotations_prepped_train/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "x_train_tif = load_tif_3bands(\"/Users/ikersanchez/Vizzuality/PROIEKTUAK/Skydipper/Data/Potsdam/2_Ortho_RGB/*_2_10_RGB.tif\")\n",
    "y_train_tif = load_tif_3bands(\"/Users/ikersanchez/Vizzuality/PROIEKTUAK/Skydipper/Data/Potsdam/5_Labels_all/*_2_10_label.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "ax = axs[0]\n",
    "ax.imshow(x_train[0,:,:,:]);\n",
    "\n",
    "ax = axs[1]\n",
    "ax.imshow(y_train[0,:,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "ax = axs[0]\n",
    "ax.imshow(x_train_tif[0,:,:,:]);\n",
    "\n",
    "ax = axs[1]\n",
    "ax.imshow(y_train_tif[0,:,:,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess class labels for Keras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the shape of our class label data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The y_train and y_test data are not split into 10 distinct class labels, but rather are represented as a single array with the class values. We can fix this easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "# Convert 1-dimensional class arrays to 12-dimensional class matrices\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=12)\n",
    "y_validation = np_utils.to_categorical(y_validation, num_classes=12)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the y_train_tif data the six categories/classes have been defined as:\n",
    "    1. Impervious surfaces (RGB: 255, 255, 255)\n",
    "    2. Building (RGB: 0, 0, 255)\n",
    "    3. Low vegetation (RGB: 0, 255, 255)\n",
    "    4. Tree (RGB: 0, 255, 0)\n",
    "    5. Car (RGB: 255, 255, 0)\n",
    "    6. Clutter/background (RGB: 255, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tif.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_rgb_to_categorical(array):\n",
    "    t = array.shape[0]\n",
    "    y = array.shape[1]\n",
    "    x = array.shape[2]\n",
    "    c = array.shape[3]\n",
    "    \n",
    "    image = np.zeros((t,y,x))\n",
    "    \n",
    "    # 0. Impervious surfaces (RGB: 255, 255, 255)\n",
    "    image[np.where((y_train_tif[:,:,:,0] == 1.) & (y_train_tif[:,:,:,1] == 1.) & (y_train_tif[:,:,:,2] == 1.))] = 0.\n",
    "    # 1. Building (RGB: 0, 0, 255)\n",
    "    image[np.where((y_train_tif[:,:,:,0] == 0.) & (y_train_tif[:,:,:,1] == 0.) & (y_train_tif[:,:,:,2] == 1.))] = 1.\n",
    "    # 2. Low vegetation (RGB: 0, 255, 255)\n",
    "    image[np.where((y_train_tif[:,:,:,0] == 0.) & (y_train_tif[:,:,:,1] == 1.) & (y_train_tif[:,:,:,2] == 1.))] = 2.\n",
    "    # 3. Tree (RGB: 0, 255, 0)\n",
    "    image[np.where((y_train_tif[:,:,:,0] == 0.) & (y_train_tif[:,:,:,1] == 1.) & (y_train_tif[:,:,:,2] == 0.))] = 3.\n",
    "    # 4. Car (RGB: 255, 255, 0)\n",
    "    image[np.where((y_train_tif[:,:,:,0] == 1.) & (y_train_tif[:,:,:,1] == 1.) & (y_train_tif[:,:,:,2] == 0.))] = 4.\n",
    "    # 5. Clutter/background (RGB: 255, 0, 0)\n",
    "    image[np.where((y_train_tif[:,:,:,0] == 1.) & (y_train_tif[:,:,:,1] == 0.) & (y_train_tif[:,:,:,2] == 0.))] = 5.\n",
    "    \n",
    "    # Convert 1-dimensional class arrays to 6-dimensional class matrices\n",
    "    image = np_utils.to_categorical(image, num_classes=6)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tif = from_rgb_to_categorical(y_train_tif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tif.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"./Samples/data1/x_train.h5\", 'w')\n",
    "f.create_dataset('x_train', data=x_train)     \n",
    "f.close()\n",
    "\n",
    "f = h5py.File(\"./Samples/data1/y_train.h5\", 'w')\n",
    "f.create_dataset('y_train', data=y_train)     \n",
    "f.close()\n",
    "\n",
    "f = h5py.File(\"./Samples/data1/x_validation.h5\", 'w')\n",
    "f.create_dataset('x_validation', data=x_validation)     \n",
    "f.close()\n",
    "\n",
    "f = h5py.File(\"./Samples/data1/y_validation.h5\", 'w')\n",
    "f.create_dataset('y_validation', data=y_validation)     \n",
    "f.close()              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train de Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_SegNet import LossHistory, train_segnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_in = \"Samples/data1/\"\n",
    "root_out = \"Network/SegNet\"\n",
    "nEpochs = 2\n",
    "option = 'start'\n",
    "\n",
    "out = train_segnet(root_in, root_out, option)\n",
    "    \n",
    "out.read_data()\n",
    "\n",
    "if (option == 'start'):           \n",
    "    out.define_network()        \n",
    "        \n",
    "if (option == 'continue'):\n",
    "    out.read_network()\n",
    "\n",
    "if (option == 'start' or option == 'continue'):\n",
    "    out.compile_network()\n",
    "    out.train_network(nEpochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SegNet import segnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'Samples/x_validation.h5'\n",
    "output_path = 'Predictions/prediction.h5'\n",
    "\n",
    "# Open file with observations and read them. We use h5 in our case\n",
    "f = h5py.File(input_path, 'r')\n",
    "imgs = f.get(\"x_validation\")\n",
    "f.close()  \n",
    "    \n",
    "prediction = segnet(imgs, output_path)\n",
    "prediction.define_network()\n",
    "out = prediction.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
