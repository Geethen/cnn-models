{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel-2 cropland mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the paper by [Belgiu & Csillik (2018)] (see also [Hao et al. 2018](https://peerj.com/articles/5431/?utm_source=TrendMD&utm_campaign=PeerJ_TrendMD_0&utm_medium=TrendMD))(https://www.sciencedirect.com/science/article/pii/S0034425717304686) we can train a CNN for the segmentation of the croplands. As an input we can use [Sentinel-2 MSI](https://sentinel.esa.int/web/sentinel/missions/sentinel-2) multispectral data, and as an output crop types data classified by experts from the European Land Use and Coverage Area Frame Survey ([LUCAS](https://ec.europa.eu/eurostat/statistics-explained/index.php/LUCAS_-_Land_use_and_land_cover_survey)) and  CropScape â€“ Cropland Data Layer ([CDL](https://nassgeodata.gmu.edu/CropScape/)), respectively.\n",
    "\n",
    "Datasets in Google Earth Engine:\n",
    "\n",
    "- [Sentinel-2 MSI: MultiSpectral Instrument, Level-1C](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2)\n",
    "- [USDA NASS Cropland Data Layers](https://developers.google.com/earth-engine/datasets/catalog/USDA_NASS_CDL)\n",
    "- [Canada AAFC Annual Crop Inventory](https://developers.google.com/earth-engine/datasets/catalog/AAFC_ACI) \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the Environment\n",
    "\n",
    "We begin by importing a number of useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "from functools import reduce\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Earth Engine client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download datasets\n",
    "We download and append datasets from different Areas of Interest (AOIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ee_datasets import ee_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central position of (AOIs)\n",
    "points = [[-120.7224, 37.3872], [-112.6799, 42.9816], [-89.7649, 35.8764], \n",
    "          [-96.0181, 41.2412], [-115.473, 46.861], [-103.9803, 47.9713], [-96.9217, 32.8958]]\n",
    "\n",
    "# Start and stop of time series\n",
    "startDate = ee.Date('2016-01-01')\n",
    "stopDate  = ee.Date('2016-12-31')\n",
    "# Scale in meters\n",
    "scale = 10\n",
    "# Buffer\n",
    "buffer = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading image...\n",
      "url:  https://earthengine.googleapis.com/api/download?docid=e1799180a8edf3be1ff76a00883f4ee9&token=639cb50f6cbdc23c82897b7c67f07364\n",
      "Download complete!\n",
      "Downloading image...\n",
      "url:  https://earthengine.googleapis.com/api/download?docid=4ce69f77412f23e0518f945bc541abbf&token=133389ed21c1776ba2475278034f8340\n",
      "Download complete!\n",
      "Downloading image...\n",
      "url:  https://earthengine.googleapis.com/api/download?docid=55d61466d74554ca28cfa03aa2ea8436&token=d79e5ecde5ab1bb36c28eec9517c2b3c\n",
      "Download complete!\n",
      "Downloading image...\n",
      "url:  https://earthengine.googleapis.com/api/download?docid=60af59604bfadbeb08c6b174f93b92a8&token=694e3d00b6cf80157ea7d43189e15188\n",
      "Download complete!\n",
      "Downloading image...\n",
      "url:  https://earthengine.googleapis.com/api/download?docid=2a9d9fada6b5b6db16b1615440c705fb&token=69e385cd70f9ddee7126ac7558ea3387\n",
      "Download complete!\n",
      "Downloading image...\n",
      "url:  https://earthengine.googleapis.com/api/download?docid=2c4758b7785c5377a50798527a0518aa&token=38be43ddb77ab5b2aebeb0cc99567529\n",
      "Download complete!\n",
      "Downloading image...\n",
      "url:  https://earthengine.googleapis.com/api/download?docid=2ec7186e80827c8853f2c42c3dfb23be&token=dfb91d298203c28c62a5f77516b1a9d8\n",
      "Download complete!\n",
      "Downloading image...\n",
      "url:  https://earthengine.googleapis.com/api/download?docid=3b565786aa6d3a51110cf68319f1f1ed&token=55b6942deff1b0861fa518c9d59145d5\n",
      "Download complete!\n",
      "Downloading image...\n",
      "url:  https://earthengine.googleapis.com/api/download?docid=9b248ea9c43714dc0674686aa7ecb32c&token=49645313f99dd5982ed2e0eabbe27901\n",
      "Download complete!\n",
      "Downloading image...\n",
      "url:  https://earthengine.googleapis.com/api/download?docid=e25e989c5b02ffe790e794e0a83d7385&token=c7769b0b6b5ab81f203d482b89066b07\n",
      "Download complete!\n",
      "Downloading image...\n",
      "url:  https://earthengine.googleapis.com/api/download?docid=015393355626e836227e89fe8401925c&token=284426330953b891547c4563c63af325\n",
      "Download complete!\n",
      "Downloading image...\n",
      "url:  https://earthengine.googleapis.com/api/download?docid=7e46828273f22904195a51e5b6e85006&token=65ba9ec85f155a93ec539b1a7f2ecb9e\n",
      "Download complete!\n",
      "Downloading image...\n",
      "url:  https://earthengine.googleapis.com/api/download?docid=08912f368a33fe2f005fbb2f2f61e1fe&token=844620c503eb47e1b9cab6ee599a4d55\n",
      "Download complete!\n",
      "Downloading image...\n",
      "url:  https://earthengine.googleapis.com/api/download?docid=fb10616dd468f70f6fc3e4b71a4e9641&token=8cd9c3287889fc6668899af3aada46c8\n",
      "Download complete!\n"
     ]
    }
   ],
   "source": [
    "dpix = 250\n",
    "for n, point in enumerate(points):\n",
    "    sentinel = ee_datasets(point = point, buffer = buffer, startDate = startDate, stopDate = stopDate, scale = scale, collection = 'Sentinel2')\n",
    "    cropland = ee_datasets(point = point, buffer = buffer, startDate = startDate, stopDate = stopDate, scale = scale, collection = 'CroplandDataLayers')\n",
    "    dataset_x = sentinel.read_datasets()\n",
    "    dataset_y = cropland.read_datasets()\n",
    "    \n",
    "    if n == 0:\n",
    "        dim_x = dataset_x.shape\n",
    "        dim_x = list(dim_x)\n",
    "        dim_x = [1] + dim_x\n",
    "        dim_x[1] = dim_x[1]-dpix; dim_x[2] = dim_x[2]-dpix\n",
    "        \n",
    "        dim_y = dataset_y.shape\n",
    "        dim_y = list(dim_y)\n",
    "        dim_y = [1] + dim_y\n",
    "        dim_y[1] = dim_y[1]-dpix; dim_y[2] = dim_y[2]-dpix\n",
    "        \n",
    "        data_x = np.zeros(dim_x, dtype=np.float32)\n",
    "        data_y = np.zeros(dim_y, dtype=np.float32)\n",
    "        \n",
    "        data_x[0,:] = dataset_x[:dim_x[1],:dim_x[2],:dim_x[3]]\n",
    "        data_y[0,:] = dataset_y[:dim_y[1],:dim_y[2],:dim_y[3]]\n",
    "    else:\n",
    "        data_x2 = np.zeros(dim_x, dtype=np.float32)\n",
    "        data_y2 = np.zeros(dim_y, dtype=np.float32)\n",
    "        \n",
    "        data_x2[0,:] = dataset_x[:dim_x[1],:dim_x[2],:dim_x[3]]\n",
    "        data_y2[0,:] = dataset_y[:dim_y[1],:dim_y[2],:dim_y[3]]\n",
    "        \n",
    "        data_x = np.append(data_x, data_x2, axis=0)\n",
    "        data_y = np.append(data_y, data_y2, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess class labels\n",
    "\n",
    "Each class in encoded as a value in the range between 0 to 254. For training a Neural Network in Keras we have to convert the 1-dimensional class arrays to N classes-dimensional matrices. To simplify the problem here we regroup all the classes into 4 categories, namely, land, water, urban, and cropland areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_data import categorical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_y = categorical_data(data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize input data\n",
    "Normalize the input channels to the range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_data import normalize_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_x = normalize_data(data_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_data import resize_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_x, new_data_y = resize_patches(new_data_x, new_data_y, patch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomize the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_data import randomize_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_randm, y_randm = randomize_datasets(new_data_x, new_data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_data import train_validation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validation, y_train, y_validation = train_validation_split(x_randm, y_randm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_data import write_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save samples\n",
    "write_data(\"../SegNet/Samples/x_train.h5\", 'x_train', x_train)\n",
    "write_data(\"../SegNet/Samples/y_train.h5\", 'y_train', y_train)\n",
    "write_data(\"../SegNet/Samples/x_validation.h5\", 'x_validation', x_validation)\n",
    "write_data(\"../SegNet/Samples/y_validation.h5\", 'y_validation', y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train SegNet from the command line type:\n",
    "\n",
    "```python\n",
    "python train_SegNet.py -i Samples/ -o Network/SegNet -e 20 -a start\n",
    "```\n",
    "\n",
    "The parameters are:\n",
    "\n",
    "```\n",
    "-i = Samples/model \n",
    "    Path of the input files.\n",
    "-o = network/model \n",
    "    Path of the output file that will contain the network weights.\n",
    "-e = 20\n",
    "    Number of epochs to use during training.\n",
    "-a = {start,continue}\n",
    "     `start`: start a new calculation\n",
    "     `continue`: continue a previous calculation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
